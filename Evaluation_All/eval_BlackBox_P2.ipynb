{"cells":[{"cell_type":"markdown","source":["## Refer to [readme.pdf](https://drive.google.com/file/d/1vbNsY0Olfs9IShPD0dxdACSXCzhT1MU9/view?usp=sharing) for detailed instructions to setup the environment before running this file.\n","\n","## Refer to the anonymised drive folder [Evaluation_All](https://drive.google.com/drive/folders/19BM3f4UeywAuhPi1xk7iJIXP0q5pi2kB?usp=sharing) for the entire setup and directory structure."],"metadata":{"id":"ZLXnpfmGpfh6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OphfqFlD4qt0"},"outputs":[],"source":["!pip install av"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6S3h8sE242Xm"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1kUYJ6a44mT"},"outputs":[],"source":["#Enter path to google drive folder\n","%cd /content/drive/MyDrive/HP_BS_T17/Evaluation_All"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVea-DiE49NJ"},"outputs":[],"source":["PATH_labelmap = \"./label_map_k600.txt\"\n","PATH_model =  './checkpoint/Blackbox_P2.pt'  #Add desired model checkpoint \n","PATH_files = './k600_val/'\n","\n","#Imports\n","import torch\n","import glob\n","import pandas as pd\n","import os\n","import re\n","from torchvision.io import read_video as rv\n","import numpy as np\n","from sklearn.metrics import top_k_accuracy_score as tkscore\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\"\"\"# Load files\"\"\"\n","\n","def class_to_label(class_):\n","    class_= re.sub(r'[^\\w\\s]', '', class_)\n","    class_ = class_.replace('_','')\n","    class_ = class_.replace(' ','')\n","    #print(class_)\n","    df=pd.read_csv(PATH_labelmap,names=['class'])\n","    df['class']=df['class'].str.replace(' ', '')\n","    df[\"class\"] = df['class'].str.replace('[^\\w\\s]','')\n","    #print(df['class'])\n","    #print(class_)\n","    ret_= df.index[df['class']==class_]\n","    #print(ret_)\n","    return ret_[0]\n","\n","def sample_class_paths(PATH, nvids):\n","    d_vid={}\n","    root,dirs,files=next(os.walk(PATH))\n","    for dir in dirs:\n","        root=str(root)\n","        dir=str(dir)\n","        _,_,file=next(os.walk(root+'/'+dir))\n","        d_vid['{}'.format(dir)]=[file[:nvids]]\n","    return d_vid\n","\n","def initialize_model(checkpoint):\n","  model = torch.load(checkpoint)\n","  model = model.eval()\n","  return model\n","\n","def parse_video(PATH):\n","    video=rv(PATH)\n","    samp=video[0]\n","    #print(samp.size())\n","    samp1= samp.type(torch.FloatTensor).permute(3,0,1,2)\n","    #samp1=samp1[:,:,:128,:128] Use in case of OOM errors\n","    #print(samp1.size())\n","    return samp1\n","\n","def eval(num_videos = 8, num_classes = 400, checkpoint = None):\n","  with torch.no_grad():\n","    true_labels = []\n","    pred_probs = []   \n","    if(checkpoint is None):\n","      print(\"Please provide model checkpont\")\n","      return False\n","    model = initialize_model(checkpoint)\n","    dict_paths = sample_class_paths(PATH_files, num_videos)\n","    counter = 0\n","    for keys in dict_paths.keys():\n","      for files in dict_paths[keys][0]:\n","        true_labels.append(class_to_label(keys))\n","        vid_tensor = parse_video(PATH_files+f'/{keys}/{files}') # Size(channels, frames, height, width)\n","        ## Error handling code for broken videos\n","        try:  \n","          model_logits = model(torch.unsqueeze(vid_tensor[:,:,:,:].cuda(),dim=1))\n","          #model_logits = model(torch.unsqueeze(vid_tensor[:,:32,:,:].cuda(),dim=0))  #Use in case of OOM error\n","        except:\n","          model_logits = torch.zeros(1,num_classes)\n","        model_probabs = torch.nn.functional.softmax(model_logits,dim=0)\n","        pred_probs.append(model_probabs)\n","        counter+=1\n","        print(f\"Video number = {counter}\")\n","\n","    true_label_arr = np.array(true_labels) # (3200,1)\n","    temp_tensor = torch.zeros(counter,num_classes)\n","    for i in range(counter):\n","      temp_tensor[i] = pred_probs[i].cpu()\n","    pred_probs_arr = np.array(temp_tensor)\n","\n","    accuracy_top5 = tkscore(true_label_arr,pred_probs_arr,k=5)\n","    print(f\"Top 5 accuracy is {accuracy_top5*100} %\")\n","    return accuracy_top5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQXl9Jlt5j_q"},"outputs":[],"source":["num_classes = 600 #Kinetics 600 dataset\n","num_videos = 24 #Number of videos from each class to pick for evaluation\n","\n","with torch.no_grad():\n","  acc = eval(checkpoint = PATH_model, num_videos = num_videos, num_classes = num_classes)"]}],"metadata":{"colab":{"name":"eval_BlackBox_P2.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}