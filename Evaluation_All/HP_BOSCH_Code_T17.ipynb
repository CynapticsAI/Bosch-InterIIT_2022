{"cells":[{"cell_type":"markdown","source":["# HP_BOSCH_T17"],"metadata":{"id":"znM3fOuOXEUT"}},{"cell_type":"markdown","metadata":{"id":"edKKVNoPPQTC"},"source":["## Code Tested on Colab Pro Plus subscription. \n","\n"]},{"cell_type":"markdown","source":["## Refer to [readme.pdf](https://drive.google.com/file/d/1vbNsY0Olfs9IShPD0dxdACSXCzhT1MU9/view?usp=sharing) for detailed instructions to setup the environment before running this file.\n","\n","## Refer to the anonymised drive folder [Evaluation_All](https://drive.google.com/drive/folders/19BM3f4UeywAuhPi1xk7iJIXP0q5pi2kB?usp=sharing) for the entire setup and directory structure."],"metadata":{"id":"OIEbu1wppE5Q"}},{"cell_type":"markdown","source":["# Black Box P1"],"metadata":{"id":"QW3-QobEG8HG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"A96cwaQEMzci"},"outputs":[],"source":["!pip install av"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDSjYiWiM97u"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUHz6rsWM29Q"},"outputs":[],"source":["#Enter path to google drive folder\n","%cd /content/drive/MyDrive/HP_BS_T17/Evaluation_All"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJnpybWEyYbZ"},"outputs":[],"source":["PATH_labelmap = \"./label_map_k400.txt\"\n","PATH_model =  './checkpoint/Blackbox_P1.pt'  #Add desired model checkpoint \n","PATH_files = './k400_val/'\n","\n","#Imports\n","import torch\n","import glob\n","import pandas as pd\n","import os\n","import re\n","from torchvision.io import read_video as rv\n","import numpy as np\n","from sklearn.metrics import top_k_accuracy_score as tkscore\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\"\"\"# Load files\"\"\"\n","\n","def class_to_label(class_):\n","    class_= re.sub(r'[^\\w\\s]', '', class_)\n","    class_ = class_.replace('_','')\n","    class_ = class_.replace(' ','')\n","    #print(class_)\n","    df=pd.read_csv(PATH_labelmap,names=['class'])\n","    df['class']=df['class'].str.replace(' ', '')\n","    df[\"class\"] = df['class'].str.replace('[^\\w\\s]','')\n","    #print(df['class'])\n","    #print(class_)\n","    ret_= df.index[df['class']==class_]\n","    #print(ret_)\n","    return ret_[0]\n","\n","def sample_class_paths(PATH, nvids):\n","    d_vid={}\n","    root,dirs,files=next(os.walk(PATH))\n","    for dir in dirs:\n","        root=str(root)\n","        dir=str(dir)\n","        _,_,file=next(os.walk(root+'/'+dir))\n","        d_vid['{}'.format(dir)]=[file[:nvids]]\n","    return d_vid\n","\n","def initialize_model(checkpoint):\n","  model = torch.load(checkpoint)\n","  model = model.eval()\n","  return model\n","\n","def parse_video(PATH):\n","    video=rv(PATH)\n","    samp=video[0]\n","    #print(samp.size())\n","    samp1= samp.type(torch.FloatTensor).permute(3,0,1,2)\n","    #samp1=samp1[:,:,:128,:128]   Use in case of OOM errors\n","    #print(samp1.size())\n","    return samp1\n","\n","def eval(num_videos = 8, num_classes = 400, checkpoint = None):\n","  with torch.no_grad():\n","    true_labels = []\n","    pred_probs = []   \n","    if(checkpoint is None):\n","      print(\"Please provide model checkpont\")\n","      return False\n","    model = initialize_model(checkpoint)\n","    dict_paths = sample_class_paths(PATH_files, num_videos)\n","    counter = 0\n","    for keys in dict_paths.keys():\n","      for files in dict_paths[keys][0]:\n","        true_labels.append(class_to_label(keys))\n","        vid_tensor = parse_video(PATH_files+f'/{keys}/{files}') # Size(channels, frames, height, width)\n","        ## Error handling code for broken videos\n","        try:  \n","          model_logits = model(torch.unsqueeze(vid_tensor[:,:,:,:].cuda(),dim=0))\n","          #model_logits = model(torch.unsqueeze(vid_tensor[:,:32,:,:].cuda(),dim=0))  #Use in case of OOM error\n","        except:\n","          model_logits = torch.zeros(1,num_classes)  \n","        model_probabs = torch.nn.functional.softmax(model_logits,dim=1)\n","        pred_probs.append(model_probabs)\n","        counter+=1\n","        print(f\"Video number = {counter}\")\n","\n","    true_label_arr = np.array(true_labels) # (3200,1)\n","    temp_tensor = torch.zeros(counter,num_classes)\n","    for i in range(counter):\n","      temp_tensor[i] = pred_probs[i].cpu()\n","    pred_probs_arr = np.array(temp_tensor)\n","\n","    accuracy_top5 = tkscore(true_label_arr,pred_probs_arr,k=5)\n","    print(f\"Top 5 accuracy is {accuracy_top5*100} %\")\n","    return accuracy_top5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ccgFfjudWPPd"},"outputs":[],"source":["num_classes = 400 #Kinetics 400 dataset\n","num_videos = 24 #Number of videos from each class to pick for evaluation\n","\n","with torch.no_grad():\n","  acc = eval(checkpoint = PATH_model, num_videos = num_videos, num_classes = num_classes)"]},{"cell_type":"markdown","source":["# Black Box P2"],"metadata":{"id":"KKLWhJjkG-aa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVea-DiE49NJ"},"outputs":[],"source":["PATH_labelmap = \"./label_map_k600.txt\"\n","PATH_model =  './checkpoint/Blackbox_P2.pt'  #Add desired model checkpoint \n","PATH_files = './k600_val/'\n","\n","#Imports\n","import torch\n","import glob\n","import pandas as pd\n","import os\n","import re\n","from torchvision.io import read_video as rv\n","import numpy as np\n","from sklearn.metrics import top_k_accuracy_score as tkscore\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\"\"\"# Load files\"\"\"\n","\n","def class_to_label(class_):\n","    class_= re.sub(r'[^\\w\\s]', '', class_)\n","    class_ = class_.replace('_','')\n","    class_ = class_.replace(' ','')\n","    #print(class_)\n","    df=pd.read_csv(PATH_labelmap,names=['class'])\n","    df['class']=df['class'].str.replace(' ', '')\n","    df[\"class\"] = df['class'].str.replace('[^\\w\\s]','')\n","    #print(df['class'])\n","    #print(class_)\n","    ret_= df.index[df['class']==class_]\n","    #print(ret_)\n","    return ret_[0]\n","\n","def sample_class_paths(PATH, nvids):\n","    d_vid={}\n","    root,dirs,files=next(os.walk(PATH))\n","    for dir in dirs:\n","        root=str(root)\n","        dir=str(dir)\n","        _,_,file=next(os.walk(root+'/'+dir))\n","        d_vid['{}'.format(dir)]=[file[:nvids]]\n","    return d_vid\n","\n","def initialize_model(checkpoint):\n","  model = torch.load(checkpoint)\n","  model = model.eval()\n","  return model\n","\n","def parse_video(PATH):\n","    video=rv(PATH)\n","    samp=video[0]\n","    #print(samp.size())\n","    samp1= samp.type(torch.FloatTensor).permute(3,0,1,2)\n","    #samp1=samp1[:,:,:128,:128] Use in case of OOM errors\n","    #print(samp1.size())\n","    return samp1\n","\n","def eval(num_videos = 8, num_classes = 400, checkpoint = None):\n","  with torch.no_grad():\n","    true_labels = []\n","    pred_probs = []   \n","    if(checkpoint is None):\n","      print(\"Please provide model checkpont\")\n","      return False\n","    model = initialize_model(checkpoint)\n","    dict_paths = sample_class_paths(PATH_files, num_videos)\n","    counter = 0\n","    for keys in dict_paths.keys():\n","      for files in dict_paths[keys][0]:\n","        true_labels.append(class_to_label(keys))\n","        vid_tensor = parse_video(PATH_files+f'/{keys}/{files}') # Size(channels, frames, height, width)\n","        ## Error handling code for broken videos\n","        try:  \n","          model_logits = model(torch.unsqueeze(vid_tensor[:,:,:,:].cuda(),dim=1))\n","          #model_logits = model(torch.unsqueeze(vid_tensor[:,:32,:,:].cuda(),dim=0))  #Use in case of OOM error\n","        except:\n","          model_logits = torch.zeros(1,num_classes)\n","        model_probabs = torch.nn.functional.softmax(model_logits,dim=0)\n","        pred_probs.append(model_probabs)\n","        counter+=1\n","        print(f\"Video number = {counter}\")\n","\n","    true_label_arr = np.array(true_labels) # (3200,1)\n","    temp_tensor = torch.zeros(counter,num_classes)\n","    for i in range(counter):\n","      temp_tensor[i] = pred_probs[i].cpu()\n","    pred_probs_arr = np.array(temp_tensor)\n","\n","    accuracy_top5 = tkscore(true_label_arr,pred_probs_arr,k=5)\n","    print(f\"Top 5 accuracy is {accuracy_top5*100} %\")\n","    return accuracy_top5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQXl9Jlt5j_q"},"outputs":[],"source":["num_classes = 600 #Kinetics 600 dataset\n","num_videos = 24 #Number of videos from each class to pick for evaluation\n","\n","with torch.no_grad():\n","  acc = eval(checkpoint = PATH_model, num_videos = num_videos, num_classes = num_classes)"]},{"cell_type":"markdown","source":["# Grey Box P1"],"metadata":{"id":"1TU073_sHLjj"}},{"cell_type":"code","source":["!pip install timm"],"metadata":{"id":"bwTSZVpVHY96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import random_split\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import timm\n","import glob\n","import pandas as pd\n","import os\n","import re\n","from torchvision.io import read_video as rv\n","import numpy as np\n","from sklearn.metrics import top_k_accuracy_score as tkscore"],"metadata":{"id":"TOM249BZrQP0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch\n","        out = self(images)  # Generate predictions\n","        loss = F.cross_entropy(out, labels)  # Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        images, labels = batch\n","        out = self(images)  # Generate predictions\n","        loss = F.cross_entropy(out, labels)  # Calculate loss\n","        acc = accuracy(out, labels)  # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()  # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","\n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","\n","\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","\n","class ResNet2DFramewise(ImageClassificationBase):\n","    def __init__(self, num_classes=400):\n","        super().__init__()\n","        self.network = timm.create_model('res2net101_26w_4s', num_classes=num_classes, pretrained=False)\n","\n","    def forward(self, xb):\n","        return self.network(xb)"],"metadata":{"id":"fSS81oMyrOHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH_labelmap = \"./label_map_k400.txt\"\n","PATH_model =  './checkpoint/Greybox_P1.pt'  #Add desired model checkpoint \n","PATH_files = './k400_val/'\n","\n","\n","transform = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","     transforms.Resize((64, 64))\n","     ])\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","def class_to_label(class_):\n","    class_= re.sub(r'[^\\w\\s]', '', class_)\n","    class_ = class_.replace('_','')\n","    class_ = class_.replace(' ','')\n","    df=pd.read_csv(PATH_labelmap,names=['class'])\n","    df['class']=df['class'].str.replace(' ', '')\n","    df[\"class\"] = df['class'].str.replace('[^\\w\\s]','')\n","    ret_= df.index[df['class']==class_]\n","    return ret_[0]\n","\n","def sample_class_paths(PATH, nvids):\n","    d_vid={}\n","    root,dirs,files=next(os.walk(PATH))\n","    for dir in dirs:\n","        root=str(root)\n","        dir=str(dir)\n","        _,_,file=next(os.walk(root+'/'+dir))\n","        d_vid['{}'.format(dir)]=[file[:nvids]]\n","    return d_vid\n","\n","def initialize_model(checkpoint):\n","  model = torch.load(checkpoint)\n","  model = model.eval()\n","  return model\n","\n","def parse_video(PATH):\n","    video=rv(PATH)\n","    samp=video[0]\n","    samp1= samp.type(torch.FloatTensor).permute(3,0,1,2)\n","    return samp1\n","\n","def eval(num_videos = 8, num_classes = 400, checkpoint = None):\n","\n","  with torch.no_grad():\n","    true_labels = []\n","    pred_probs = []   \n","    if(checkpoint is None):\n","      print(\"Please provide checkpoint path\")\n","      return False\n","\n","    model = ResNet2DFramewise().cuda()\n","    state_dict = torch.load(PATH_model)\n","    model.load_state_dict(state_dict[\"model\"])\n","\n","    dict_paths = sample_class_paths(PATH_files, num_videos)\n","    counter = 0\n","    for keys in dict_paths.keys():\n","      for files in dict_paths[keys][0]:\n","        true_labels.append(class_to_label(keys))\n","        vid_tensor = parse_video(PATH_files+f'/{keys}/{files}')\n","        number_of_frames = vid_tensor.shape[1]\n","        desired_frame_number = number_of_frames//2\n","        desired_frame = torch.unsqueeze(vid_tensor[:,desired_frame_number,:,:].cuda(),dim=0)\n","        desired_frame = transform(desired_frame)\n","        model_logits = model(desired_frame).cuda()  \n","        model_probabs = torch.nn.functional.softmax(model_logits, dim=1)\n","        pred_probs.append(model_probabs)\n","        counter+=1\n","        print(f\"Video number = {counter}\")\n","\n","    true_label_arr = np.array(true_labels)\n","    temp_tensor = torch.zeros(counter,num_classes)\n","    for i in range(counter):\n","      temp_tensor[i] = pred_probs[i].cpu()\n","    pred_probs_arr = np.array(temp_tensor)\n","\n","    accuracy_top5 = tkscore(true_label_arr,pred_probs_arr,k=5)\n","    print(f\"Top 5 accuracy is {accuracy_top5*100} %\")\n","    return accuracy_top5\n","\n","num_videos = 24\n","\n","with torch.no_grad():\n","  acc = eval(checkpoint = PATH_model, num_videos)"],"metadata":{"id":"exCdliuRrSjJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Grey Box P2"],"metadata":{"id":"so3n70Q_Hboa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxUhbzkaHhzy"},"outputs":[],"source":["PATH_labelmap = \"./label_map_k600.txt\"\n","PATH_model =  './checkpoint/Greybox_P2.pt'  #Add desired model checkpoint \n","PATH_files = './k600_val/'\n","\n","#Imports\n","import torch\n","import glob\n","import pandas as pd\n","import os\n","import re\n","from torchvision.io import read_video as rv\n","import numpy as np\n","from sklearn.metrics import top_k_accuracy_score as tkscore\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\"\"\"# Load files\"\"\"\n","\n","def class_to_label(class_):\n","    class_= re.sub(r'[^\\w\\s]', '', class_)\n","    class_ = class_.replace('_','')\n","    class_ = class_.replace(' ','')\n","    #print(class_)\n","    df=pd.read_csv(PATH_labelmap,names=['class'])\n","    df['class']=df['class'].str.replace(' ', '')\n","    df[\"class\"] = df['class'].str.replace('[^\\w\\s]','')\n","    #print(df['class'])\n","    #print(class_)\n","    ret_= df.index[df['class']==class_]\n","    #print(ret_)\n","    return ret_[0]\n","\n","def sample_class_paths(PATH, nvids):\n","    d_vid={}\n","    root,dirs,files=next(os.walk(PATH))\n","    for dir in dirs:\n","        root=str(root)\n","        dir=str(dir)\n","        _,_,file=next(os.walk(root+'/'+dir))\n","        d_vid['{}'.format(dir)]=[file[:nvids]]\n","    return d_vid\n","\n","def initialize_model(checkpoint):\n","  model = torch.load(checkpoint)\n","  model = model.eval()\n","  return model\n","\n","def parse_video(PATH):\n","    video=rv(PATH)\n","    samp=video[0]\n","    #print(samp.size())\n","    samp1= samp.type(torch.FloatTensor).permute(3,0,1,2)\n","    #samp1=samp1[:,:,:128,:128] Use in case of OOM errors\n","    #print(samp1.size())\n","    return samp1\n","\n","def eval(num_videos = 8, num_classes = 400, checkpoint = None):\n","  with torch.no_grad():\n","    true_labels = []\n","    pred_probs = []   \n","    if(checkpoint is None):\n","      print(\"Please provide model checkpont\")\n","      return False\n","    model = initialize_model(checkpoint)\n","    dict_paths = sample_class_paths(PATH_files, num_videos)\n","    counter = 0\n","    for keys in dict_paths.keys():\n","      for files in dict_paths[keys][0]:\n","        true_labels.append(class_to_label(keys))\n","        vid_tensor = parse_video(PATH_files+f'/{keys}/{files}') # Size(channels, frames, height, width)\n","        ## Error handling code for broken videos\n","        try:  \n","          model_logits = model(torch.unsqueeze(vid_tensor[:,:,:,:].cuda(),dim=1))\n","          #model_logits = model(torch.unsqueeze(vid_tensor[:,:32,:,:].cuda(),dim=0))  #Use in case of OOM error\n","        except:\n","          model_logits = torch.zeros(1,num_classes)\n","        model_probabs = torch.nn.functional.softmax(model_logits,dim=0)\n","        pred_probs.append(model_probabs)\n","        counter+=1\n","        print(f\"Video number = {counter}\")\n","\n","    true_label_arr = np.array(true_labels) # (3200,1)\n","    temp_tensor = torch.zeros(counter,num_classes)\n","    for i in range(counter):\n","      temp_tensor[i] = pred_probs[i].cpu()\n","    pred_probs_arr = np.array(temp_tensor)\n","\n","    accuracy_top5 = tkscore(true_label_arr,pred_probs_arr,k=5)\n","    print(f\"Top 5 accuracy is {accuracy_top5*100} %\")\n","    return accuracy_top5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qx0tWGROHhzy"},"outputs":[],"source":["num_classes = 600 #Kinetics 600 dataset\n","num_videos = 24 #Number of videos from each class to pick for evaluation\n","\n","with torch.no_grad():\n","  acc = eval(checkpoint = PATH_model, num_videos = num_videos, num_classes = num_classes)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"HP_BOSCH_Code_T17.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}